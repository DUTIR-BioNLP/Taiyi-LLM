[ **English** | [ä¸­æ–‡](./README_ZH.md) \]
<p align="center">
    <br>
    <img src="./fig/logo-all.png?raw=true" width="800" height="381"/>
    <br>
</p>


<p align="center">
        ğŸ¤— <a href="https://huggingface.co/DUTIR-BioNLP/Taiyi-LLM">Hugging Face</a>&nbsp&nbsp | &nbsp&nbspğŸ¤– <a href="https://modelscope.cn/models/DUTIRbionlp/Taiyi-LLM/">ModelScope<a>&nbsp&nbsp | &nbsp&nbspğŸ–¥ï¸ <a href="https://u230271-8d67-862a10ff.westb.seetacloud.com:8443/">Demo</a>&nbsp&nbsp | ğŸ“ƒ<a href="./data_file/dataset_inf.md">DatasetInf</a>&nbsp&nbsp | &nbsp&nbsp <a href="https://mp.weixin.qq.com/s/HlyzalsxdNy6yFV2iGqbBQ">WeChat (å¾®ä¿¡)</a>
<br>
<br>
</p>

# Taiyi (å¤ªä¸€): A Bilingual (Chinese and English) Fine-Tuned Large Language Model for Diverse Biomedical Tasks

**Project Background**

With the rapid development of deep learning technology, large language models (LLMs) like ChatGPT have made significant progress in the field of natural language processing. In the context of biomedical applications, large language models facilitate communication between healthcare professionals and patients, provide valuable medical information, and have enormous potential in assisting diagnosis, biomedical knowledge discovery, drug development, and personalized healthcare solutions, among others. However, in the AI community, there is a relative scarcity of existing open-source biomedical large models, with most of them primarily focused on monolingual medical question-answering dialogues in either Chinese or English. Therefore, this project embarks on research dedicated to large models for the biomedical domain and introduces the first version of a bilingual (Chinese and English) biomedical large language model named 'Taiyi', aiming to explore the capabilities of large models in handling a variety of bilingual natural language processing tasks in the biomedical field.


**Project Highlights**

- **Rich Biomedical Training Resources**ï¼šFor the biomedical domain, this project has collected and organized a diverse set of bilingual (Chinese and English) Biomedical Natural Language Processing (BioNLP) training datasets. This collection includes a total of 38 Chinese datasets covering 10 BioNLP tasks and 102 English datasets covering 12 BioNLP tasks. To facilitate task-specific requirements, standardized data formats have been designed and applied for consistent formatting across all datasets.
- **Promising Bilingual BioNLP Multi-Task Capability**ï¼šUsing rich bilingual instruction data (over 1 million samples) to fine-tune the LLM, the model show the bilingual capability in various BioNLP tasks including intelligent biomedical question-answering, biomedical dialogues, report generation, information extraction, machine translation, title generation, text classification, and more.
- **Outstanding Generalization Capability** Besides the biomedical conversation abilities, the model still retains general domain conversation abilities. Through the design of diverse instruction templates, it exhibits good generalization across various scenarios of similar tasks, and even stimulates the model's ability for zero-shot learning.
  
To promote the development of NLP in the biomedical field, this project releases Chinese-English BioNLP dataset curation details, Taiyi large model weights, and model inference usage scripts.

**Overview of Framework**

<p align="center">
    <br>
    <img src="./fig/overview_en.png?raw=true" width="900" height="451"/>
    <br>
</p>

## Contents
- [Taiyi (å¤ªä¸€)ï¼šA Bilingual (Chinese and English) Biomedical Large Language Model Finetuned with Rich Biomedical Data](#taiyi-å¤ªä¸€a-bilingual-chinese-and-english-biomedical-large-language-model-finetuned-with-rich-biomedical-data)
  - [Contents](#contents)
  - [Use Cases](#use-cases)
    - [1. Question Answering](#1-question-answering)
    - [2. Biomedical Dialogue](#2-biomedical-dialogue)
    - [3. Medical Report Generation](#3-medical-report-generation)
    - [4. Biomedical Information Extraction](#4-biomedical-information-extraction)
      - [4.1 Named Entity Recognition](#41-named-entity-recognition)
      - [4.2 Relation Extraction](#42-relation-extraction)
      - [4.3 Event Extraction](#43-event-extraction)
    - [5. Machine Translation](#5-machine-translation)
    - [6. Title Generation](#6-title-generation)
    - [7. Text Classification](#7-text-classification)
    - [8. Text Semantic Similarity](#8-text-semantic-similarity)
  - [Training Data](#training-data)
    - [Data Collection](#data-collection)
    - [Standardized Data Format](#standardized-data-format)
    - [Instruction-Tuning Data](#instruction-tuning-data)
  - [Model Training](#model-training)
    - [Introduction to the Base Model](#introduction-to-the-base-model)
    - [Training Details](#training-details)
  - [Model Usage](#model-usage)
    - [Environment Setup](#environment-setup)
    - [Model Inference](#model-inference)
  - [Overall Performance](#overall-performance)
  - [Limitation and Future Work](#limitation-and-future-work)
  - [Development Team](#development-team)
  - [Acknowledgements](#acknowledgements)
  - [Disclaimer](#disclaimer)
  - [Citation](#citation)
  - [Star History](#star-history)



## Use Cases
### 1. Question Answering
**Task Introduction**

Biomedical question answering is designed to assist users in obtaining answers and information related to the field of biomedical science through a question-and-answer format. It contributes to more effective management of biomedical information, enhances the quality of medical decision-making, and improves the effectiveness of biomedical education.

<details>
  <summary><b>Examples</b></summary>

**Example in Chinese**


```
ç”¨æˆ·ï¼šæœ€è¿‘è‚šå­æ€»æ˜¯éšéšä½œç—›ï¼Œæ„Ÿè§‰èƒ€èƒ€çš„ï¼Œåƒä¸‹å»çš„ä¸œè¥¿éƒ½æ²¡æ³•å¸æ”¶ï¼Œèƒƒç–¼çš„ç‰¹åˆ«å‰å®³ï¼Œå¶å°”ä¼´æœ‰æ¶å¿ƒæƒ³åçš„æ„Ÿè§‰ï¼Œè¯·é—®æ˜¯ä»€ä¹ˆå›äº‹ï¼Ÿ
å¤ªä¸€ï¼šæ‚¨å¥½ï¼Œæ ¹æ®æ‚¨çš„æè¿°ï¼Œæ‚¨å¯èƒ½æ­£åœ¨ç»å†èƒƒè‚ é“ä¸é€‚çš„ç—‡çŠ¶ã€‚è¿™äº›ç—‡çŠ¶å¯èƒ½æ˜¯ç”±å¤šç§åŸå› å¼•èµ·çš„ï¼Œä¾‹å¦‚æ¶ˆåŒ–ä¸è‰¯ã€èƒƒç‚ã€èƒƒæºƒç–¡ã€èƒ†å›Šç‚ã€èƒ†å›Šç»“çŸ³ç­‰ã€‚å»ºè®®æ‚¨å°½å¿«å°±åŒ»ï¼Œè¿›è¡Œç›¸å…³æ£€æŸ¥ä»¥ç¡®å®šç—…å› ï¼Œå¹¶æ ¹æ®åŒ»ç”Ÿçš„å»ºè®®è¿›è¡Œæ²»ç–—ã€‚åŒæ—¶ï¼Œæ‚¨å¯ä»¥æ³¨æ„é¥®é£Ÿï¼Œé¿å…è¾›è¾£ã€æ²¹è…»ã€åˆºæ¿€æ€§é£Ÿç‰©ï¼Œå¤šå–æ°´ï¼Œä¿æŒè‰¯å¥½çš„ç”Ÿæ´»ä¹ æƒ¯ï¼Œé¿å…è¿‡åº¦åŠ³ç´¯å’Œæƒ…ç»ªæ³¢åŠ¨ã€‚å¸Œæœ›æ‚¨æ—©æ—¥åº·å¤ã€‚
```

**Example in English**


```
Userï¼šWhat is the best treatment for sleep problems?
Taiyiï¼šThe best treatment for sleep problems depends on the specific cause of the sleep problem. There are many different factors that can contribute to sleep problems, including sleep disorders, stress, anxiety, depression, medication, and lifestyle habits. Some common treatments for sleep problems include:
1. Cognitive-behavioral therapy (CBT) for sleep disorders, which is a type of talk therapy that helps people identify and change negative thoughts and behaviors that are interfering with their sleep.
2. Relaxation techniques, such as deep breathing, progressive muscle relaxation, and visualization, which can help people relax and fall asleep.
3. Sleep hygiene, which is a set of practices that promote healthy sleep habits, such as avoiding caffeine and electronics before bedtime, maintaining a regular sleep schedule, and creating a relaxing bedtime routine.
4. Medications, such as sleep aids, which can help people fall asleep and stay asleep, but may have side effects and risks.
5. Lifestyle changes, such as exercise, avoiding alcohol and nicotine, and creating a relaxing bedtime routine, which can all help improve sleep quality..
```
</details>

### 2. Biomedical Dialogue
**Task Introduction**

The Taiyi model is capable of simulating natural language conversations between medical experts and patients. These conversations can encompass various biomedical topics, including medical inquiries, disease prevention, medication consultations, and more.

<details>
  <summary><b>Examples</b></summary>

**Example in Chinese**

```
ç”¨æˆ·ï¼šä»€ä¹ˆæ˜¯é¼ ç–«ï¼Ÿ
å¤ªä¸€ï¼šé¼ ç–«æ˜¯ç”±é¼ ç–«æ†èŒå¼•èµ·çš„ä¼ æŸ“ç—…ï¼Œé¼ ç–«æ†èŒæ˜¯ä¸€ç§ç»†èŒï¼Œé€šå¸¸é€šè¿‡è·³èš¤å®å’¬ä¼ æ’­ã€‚é¼ ç–«æ†èŒä¸»è¦å­˜åœ¨äºå•®é½¿ç±»åŠ¨ç‰©çš„ï¼Œå¦‚è€é¼ ã€åœŸæ‹¨é¼ ç­‰ï¼Œå½“è¿™äº›åŠ¨ç‰©è¢«æ„ŸæŸ“åï¼Œå®ƒä»¬ä¼šé€šè¿‡è·³èš¤å®å’¬ä¼ æ’­ç»™å…¶ä»–åŠ¨ç‰©ï¼ŒåŒ…æ‹¬äººç±»ã€‚é¼ ç–«æ†èŒä¸»è¦é€šè¿‡è·³èš¤å®å’¬ä¼ æ’­ï¼Œä¹Ÿå¯ä»¥é€šè¿‡ç›´æ¥æ¥è§¦æ„ŸæŸ“ã€‚
ç”¨æˆ·ï¼šå®ƒæœ‰ä»€ä¹ˆé¢„é˜²æ–¹æ³•å—ï¼Ÿ
å¤ªä¸€ï¼š
é¢„é˜²é¼ ç–«çš„æ–¹æ³•åŒ…æ‹¬ä»¥ä¸‹å‡ ç‚¹ï¼š
é¿å…æ¥è§¦æ„ŸæŸ“æºï¼šå°½é‡é¿å…æ¥è§¦å•®é½¿ç±»åŠ¨ç‰©ï¼Œå¦‚è€é¼ ã€åœŸæ‹¨é¼ ç­‰ï¼Œç‰¹åˆ«æ˜¯åœ¨ç–«åŒºæˆ–ç–«åŒºé™„è¿‘ã€‚
ä¿æŒä¸ªäººå«ç”Ÿï¼šå‹¤æ´—æ‰‹ï¼Œä¿æŒèº«ä½“æ¸…æ´ï¼Œé¿å…æ¥è§¦æ„ŸæŸ“æºã€‚
é£Ÿç”¨å®‰å…¨é£Ÿå“ï¼šåœ¨ç–«åŒºæˆ–ç–«åŒºé™„è¿‘ï¼Œå°½é‡é¿å…é£Ÿç”¨æœªç»ç…®ç†Ÿçš„è‚‰ç±»ã€è›‹ç±»ç­‰é£Ÿå“ã€‚
åšå¥½é˜²æŠ¤æªæ–½ï¼šåœ¨ç–«åŒºæˆ–ç–«åŒºé™„è¿‘ï¼Œä½©æˆ´å£ç½©ã€æ‰‹å¥—ç­‰é˜²æŠ¤ç”¨å“ï¼Œé¿å…ç›´æ¥æ¥è§¦æ„ŸæŸ“æºã€‚
æ¥ç§ç–«è‹—ï¼šåœ¨ç–«åŒºæˆ–ç–«åŒºé™„è¿‘ï¼Œå¯ä»¥æ¥ç§é¼ ç–«ç–«è‹—ï¼Œå¢å¼ºå…ç–«åŠ›ï¼Œé¢„é˜²æ„ŸæŸ“ã€‚
ç”¨æˆ·ï¼šé¼ ç–«å¸¸å‘ç”Ÿåœ¨å“ªäº›å›½å®¶ï¼Ÿ
å¤ªä¸€ï¼šé¼ ç–«æ˜¯ä¸€ç§å…¨çƒæ€§ä¼ æŸ“ç—…ï¼Œä¸»è¦åˆ†å¸ƒåœ¨æ¸©å¸¦å’Œå¯’å¸¦åœ°åŒºã€‚ç›®å‰ï¼Œé¼ ç–«ä¸»è¦åˆ†å¸ƒåœ¨äºšæ´²ã€éæ´²å’Œæ¬§æ´²ç­‰åœ°åŒºã€‚å…¶ä¸­ï¼Œäºšæ´²åœ°åŒºæ˜¯é¼ ç–«çš„ä¸»è¦æµè¡ŒåŒºï¼ŒåŒ…æ‹¬ä¸­å›½ã€è’™å¤ã€ä¿„ç½—æ–¯ã€æœé²œã€éŸ©å›½ã€æ—¥æœ¬ç­‰å›½å®¶ã€‚éæ´²åœ°åŒºæ˜¯é¼ ç–«çš„é«˜å‘åŒºï¼ŒåŒ…æ‹¬éæ´²ä¸­éƒ¨ã€å—éƒ¨ã€ä¸œéƒ¨ç­‰åœ°åŒºã€‚æ¬§æ´²åœ°åŒºæ˜¯é¼ ç–«çš„é«˜å‘åŒºï¼ŒåŒ…æ‹¬æ¬§æ´²ä¸­éƒ¨ã€åŒ—éƒ¨ã€ä¸œéƒ¨ç­‰åœ°åŒºã€‚
```

**Example in English**

```
Userï¼šDo you know colchicine?
Taiyiï¼šColchicine is a medication used to treat gout, a type of arthritis that causes joint pain, swelling, and redness. It works by reducing the amount of uric acid in the body.
Userï¼šDoes it have any potential side effects?
Taiyiï¼šYes, Colchicine can have potential side effects. Some of the common side effects of Colchicine include nausea, vomiting, diarrhea, abdominal pain, and loss of appetite. However, there are also some rare but serious side effects of Colchicine, such as muscle weakness, confusion, and difficulty breathing. If you experience any of these side effects, you should seek medical attention immediately.
```
</details>

### 3. Medical Report Generation
**Task Introduction**

Medical report auto-generation aims to summarize information during the diagnostic process. The task requires the language model to generate medical reports in a specified format based on patient self-reports and doctor-patient dialogues. This task can assist doctors in handling a large volume of medical information more effectively and provide accurate diagnoses and treatment recommendations to patients.

<details>
  <summary><b>Examples</b></summary>

**Example in Chinese**

**User Inputï¼š** 
```
é—®è¯Šå¯¹è¯å†å²ï¼š
æ‚£è€…ï¼šå°å­©å—å‡‰äº†ï¼Œæµæ¸…é¼»æ¶•ï¼Œå’³å—½ï¼Œåº”è¯¥æ˜¯é£å¯’å’³å—½ï¼Œå»è¯åº—ä¹°å“ªç§è¯å¥½å‘¢
åŒ»ç”Ÿï¼šä½ å¥½ï¼Œå®å®å’³å—½ï¼Œæµæ¶•æ¯”è¾ƒå¸¸è§ï¼Œè¥¿åŒ»è§’åº¦ä¸Šå‘¼å¸é“æ„ŸæŸ“å¯èƒ½æ€§å¤§ï¼Œä¸­åŒ»ä¸Šå«åšé£å¯’å’³å—½ï¼Œè¯·é—®å®å®é™¤äº†å’³å—½æœ‰æ²¡æœ‰å…¶ä»–ä¸é€‚ç—‡çŠ¶å‘¢ï¼Ÿä¾‹å¦‚å‘çƒ­ç­‰ï¼Œè¯·è¯¦ç»†æè¿°ä¸€ä¸‹ï¼Œæˆ‘å¥½å¸®ä½ è¯Šæ²»åˆ†æç—…æƒ…
æ‚£è€…ï¼šç²¾ç¥çŠ¶æ€å¥½ï¼Œä¹Ÿæ²¡æœ‰å‘çƒ­ï¼Œå°±æ˜¯å–‰å’™æœ‰ä¸€ç‚¹ç—›ï¼Œå’³å—½
åŒ»ç”Ÿï¼šå…ˆå¸®ä½ åˆ†æä¸€ä¸‹ç—…æƒ…ï¼Œå®å®å—å‡‰ä¹‹åå…ç–«åŠ›é™ä½ï¼Œå°±ä¼šè¢«ç»†èŒæˆ–ç—…æ¯’ä¾µè¢­ä½“å†…ï¼Œæ°”é“åˆ†æ³Œç‰©å¢å¤šï¼Œæ”¯æ°”ç®¡å¹³æ»‘è‚Œç—‰æŒ›ï¼Œå’³å—½ï¼Œå’³ç—°ï¼Œå’½é€šã€‚
åŒ»ç”Ÿï¼šç›®å‰æ²¡æœ‰å‘çƒ­ï¼Œå®å®ç—…æƒ…ä¸é‡ï¼Œä¸ç”¨è¿‡åˆ†ç´§å¼ çš„ã€‚
åŒ»ç”Ÿï¼šæˆ‘å¸®æ¨èæ²»ç–—æ–¹æ³•
åŒ»ç”Ÿï¼šå®å®ç›®å‰å¤šå¤§äº†ï¼Ÿæœ‰æ²¡æœ‰å†åŒ»é™¢çœ‹è¿‡ï¼Ÿåšè¿‡åŒ–éªŒæ£€æŸ¥
æ‚£è€…ï¼šå—¯
æ‚£è€…ï¼š7å²ï¼Œæ²¡å»åŒ»é™¢ï¼Œåšè¿‡å¾ˆå¤šæ£€æŸ¥ï¼Œå¹³å¸¸å°±æ˜¯çˆ±å’³å—½ï¼Œå–‰å“å‘ç‚
æ‚£è€…ï¼šåŒ»ç”Ÿè¯´ï¼Œæ‰æ¡ƒä½“åå¤§
åŒ»ç”Ÿï¼šè¿‘æœŸè¿™æ¬¡æœ‰æ²¡æœ‰å»åŒ»é™¢çœ‹è¿‡ï¼Ÿåšè¿‡æ£€æŸ¥
åŒ»ç”Ÿï¼šå¦‚æœå®å®æ²¡æœ‰å…¶ä»–ä¸é€‚ï¼Ÿå¯ä»¥å£æœæ°¨æº´ç´¢ï¼Œæ¡”è´åˆå‰‚æ•ˆæœå¥½
åŒ»ç”Ÿï¼šå¦å¤–å¦‚æœæ¡ä»¶å…è®¸ï¼Œå¯ä»¥åšåšé›¾åŒ–å¸å…¥æ²»ç–—ç›´æ¥ä½œç”¨ä¸æ”¯æ°”ç®¡ç²˜è†œï¼Œæ•ˆæœæ›´ç›´æ¥
æ‚£è€…ï¼šä¸ç”¨åšé›¾åŒ–å§ï¼Œåƒç‚¹è¯å°±è¡Œäº†
åŒ»ç”Ÿï¼šä¹Ÿå¯ä»¥å…ˆåƒè¯
æ‚£è€…ï¼šè¿‘æœŸæ²¡æœ‰å»è¿‡
åŒ»ç”Ÿï¼šä½ ä»¬è¿™æ¬¡æ²¡æœ‰å»åŒ»é™¢çœ‹è¿‡ï¼Ÿ
æ‚£è€…ï¼šè¦åƒæ¶ˆç‚çš„å—
æ‚£è€…ï¼šæ²¡
æ‚£è€…ï¼šè¦åƒæ¶ˆç‚è¯å—
åŒ»ç”Ÿï¼šä½ å¥½ï¼Œå¯ä»¥å…ˆä¸åƒçš„
æ‚£è€…ï¼šé‚£å®¶é‡Œæœ‰è’²åœ°è“ï¼Œå¯ä»¥åƒå—
æ‚£è€…ï¼šå£æœæ¶²
æ‚£è€…ï¼šå–‰å“ç—›è¦åƒå—
åŒ»ç”Ÿï¼šå…ˆæ²»ç–—çœ‹çœ‹ï¼Œå¯ä»¥åƒçš„ï¼Œå‡å¦‚å®å®å‡ºç°å‘çƒ­æˆ–å’³å—½åŠ é‡ï¼ŒåŒ»é™¢å°±è¯Šï¼Œå¤æŸ¥è¡€å¸¸è§„å’Œèƒ¸ç‰‡ï¼Œé‚£ä¸ªæ—¶å€™å†è€ƒè™‘åŠ æŠ—ç”Ÿç´ 
æ‚£è€…ï¼šå¦å¤–ä¹°ä¸ªæ­¢å’³çš„ï¼Œè¡Œå—
åŒ»ç”Ÿï¼šæˆ‘ä»¬çš„è§‚ç‚¹æ˜¯å®å®å°ï¼Œå°½é‡å°‘åƒæ¶ˆç‚è¯ï¼Œå¯ä»¥å…ˆåƒé‚£å‡ ä¸ªè¯ä¸‰å¤©çœ‹çœ‹æ•ˆæœ
æ‚£è€…ï¼šå—¯è°¢è°¢
æ ¹æ®ä¸Šè¿°å¯¹è¯ï¼Œç»™å‡ºè¯Šç–—æŠ¥å‘Š
è¯´æ˜ï¼šè¯Šç–—æŠ¥å‘Šåˆ†ä¸ºä¸»è¯‰, ç°ç—…å², è¾…åŠ©æ£€æŸ¥, æ—¢å¾€å², è¯Šæ–­, å»ºè®®è¿™å…­ä¸ªç« èŠ‚ã€‚
```
**Taiyi Outputï¼š**  
```   
ä¸Šè¿°é—®è¯Šå¯¹è¯çš„è¯Šç–—æŠ¥å‘Šå¦‚ä¸‹ï¼š
ä¸»è¯‰ï¼šå’³å—½ã€æµæ¶•ã€‚
ç°ç—…å²ï¼šæ‚£å„¿æ— æ˜æ˜¾è¯±å› ä¸‹å‡ºç°å’³å—½ã€æµæ¶•ï¼Œæ— æ¶å¿ƒå‘•åï¼Œæ— å…¶ä»–æ˜æ˜¾ä¸é€‚ç—‡çŠ¶ã€‚ç²¾ç¥çŠ¶æ€ä¸€èˆ¬ï¼Œèƒƒçº³ä¸€èˆ¬ï¼Œä½™å¦‚å¸¸ã€‚
è¾…åŠ©æ£€æŸ¥ï¼šæš‚æ— ã€‚
æ—¢å¾€å²ï¼šæ—¢å¾€ä½“å¥ã€‚
è¯Šæ–­ï¼šå°å„¿å’³å—½ã€‚
å»ºè®®ï¼šå£æœæ°¨æº´ç´¢ã€æ¡”è´åˆå‰‚ï¼Œå¯†è§‚ã€‚
```    

</details>

### 4. Biomedical Information Extraction
#### 4.1 Named Entity Recognition
**Task Introduction**

Biomedical named entity recognition aims to identify predefined biomedical entities from text. These entities can include biomedical concepts such as diseases, drugs, genes, proteins, and more.

<details>
  <summary><b>Examples</b></summary>

**Example in Chinese**

**User Inputï¼š** 
``` 
ä»ä¸‹é¢æ–‡æœ¬ä¸­è¯†åˆ«å‡ºæŒ‡å®šçš„å®ä½“ç±»å‹ï¼š
æ²»ç–—ä»¥é€‰ç”¨å¤§ç¯å†…é…¯ç±»æŠ—ç”Ÿç´ ï¼Œæ²™çœ¼è¡£åŸä½“è‚ºç‚ä¹Ÿå¯ç”¨ç£ºèƒºäºŒç”²åŸºå¼‚å”‘ï¼Œå¹´é•¿å„¿å’Œæˆäººç”¨æ°Ÿå–¹è¯ºé…®ç±»æ•ˆæœä¹Ÿå¾ˆå¥½ã€‚
å®ä½“ç±»å‹ï¼šç–¾ç—…ï¼Œè¯ç‰©
``` 
**Taiyi Outputï¼š**
``` 
ç–¾ç—…ï¼šæ²™çœ¼è¡£åŸä½“è‚ºç‚
è¯ç‰©ï¼šå¤§ç¯å†…é…¯ç±»æŠ—ç”Ÿç´ ; ç£ºèƒºäºŒç”²åŸºå¼‚å”‘; æ°Ÿå–¹è¯ºé…®ç±»
``` 

**Example in English**

**User Inputï¼š** 
``` 
Extract the gene, disease entities from the following text:
Identification of a novel FBN1 gene mutation in a Chinese family with Marfan syndrome.
``` 
**Taiyi Outputï¼š**
``` 
gene: FBN1
disease: Marfan syndrome
``` 
</details>

#### 4.2 Relation Extraction
**Task Introduction**

Biomedical relationship extraction aims to automatically extract predifined relationships or associations between biomedical entities from text, such as interactions between proteins and genes, therapeutic relationships between drugs and diseases, and more.

<details>
  <summary><b>Examples</b></summary>

**Example in Chinese**

**User Inputï¼š** 
``` 
ç»™å‡ºå¥å­ä¸­è¯ç‰©æ²»ç–—å…³ç³»ç±»å‹çš„å®ä½“å¯¹ï¼šæ…¢æ€§é˜»å¡æ€§è‚ºç–¾ç—…@å‡å°‘æ€¥æ€§åŠ é‡ï¼šæœ‰é«˜è´¨é‡çš„è¯æ®è¯å®ï¼ŒÎ²2 å—ä½“æ¿€åŠ¨å‰‚åœ¨å‡å°‘ 12-52 å‘¨æ€¥æ€§åŠ é‡æ–¹é¢æ¯”å®‰æ…°å‰‚æ›´æœ‰æ•ˆã€‚
``` 
**Taiyi Outputï¼š**
``` 
å…·æœ‰è¯ç‰©æ²»ç–—å…³ç³»çš„å®ä½“å¯¹å¦‚ä¸‹ï¼š[æ…¢æ€§é˜»å¡æ€§è‚ºç–¾ç—…, Î²2 å—ä½“æ¿€åŠ¨å‰‚]
``` 

**Example in English**

**User Inputï¼š** 
``` 
Find the relations of drug entity pairs in the textï¼š
Mitotane has been reported to accelerate the metabolism of warfarin by the mechanism of hepatic microsomal enzyme induction, leading to an increase in dosage requirements for warfarin. Therefore, physicians should closely monitor patients for a change in anticoagulant dosage requirements when administering Mitotane to patients on coumarin-type anticoagulants. In addition, Mitotane should be given with caution to patients receiving other drugs susceptible to the influence of hepatic enzyme induction.
Relation Types: ADVISE, MECHANISM, EFFECT, INT
``` 
**Taiyi Outputï¼š**
``` 
ADVISE: [Mitotane, coumarin-type anticoagulants]
MECHANISM: [Mitotane, warfarin]
``` 
</details>


#### 4.3 Event Extraction
**Task Introduction**

Biomedical event extraction is to extract structured biomedical events from unstructured and vast biomedical literature, mining the described biological entities in the literature, as well as the fine-grained relationships between biomedical events. This task can save time in manually reviewing literature and provide support for the construction of relevant databases, disease diagnosis, prevention research, and more.

<details>
  <summary><b>Examples</b></summary>

**Example in Chinese**

**User Inputï¼š** 
``` 
æ‰¾å‡ºæŒ‡å®šçš„ä¸´åºŠå‘ç°äº‹ä»¶å±æ€§ï¼š
å› æ‚£è€…éœ€æœŸæœ«è€ƒè¯•ï¼Œæ•…äºˆä»¥å£æœâ€œé›·è´æ‹‰å”‘é’ è‚ æº¶ç‰‡â€æ²»ç–—ï¼Œç°è…¹ç—›æƒ…å†µæ˜æ˜¾å¥½è½¬ã€‚
äº‹ä»¶æŠ½å–è¯´æ˜ï¼šä¸´åºŠå‘ç°äº‹ä»¶ç”±ä¸»ä½“è¯ï¼Œå‘ç”ŸçŠ¶æ€ï¼Œæè¿°è¯å’Œè§£å‰–éƒ¨ä½ç»„æˆ
``` 
**Taiyi Outputï¼š**
``` 
ä¸Šè¿°å¥å­ä¸­çš„ä¸´åºŠå‘ç°äº‹ä»¶å¦‚ä¸‹ï¼š
ä¸»ä½“è¯ï¼šç–¼ç—›ï¼›å‘ç”ŸçŠ¶æ€ï¼šï¼›æè¿°è¯ï¼šæ˜æ˜¾å¥½è½¬ï¼›è§£å‰–éƒ¨ä½ï¼šè…¹
``` 

**Example in English**

**User Inputï¼š** 
``` 
Input text: "Contaminated drinking water is responsible for causing diarrheal diseases that kill millions of people a year.
Even Types: Treatment of disease, Cause of disease
Role Types: Cause, Theme
Please extract events from the input text.
``` 
**Taiyi Outputï¼š**
``` 
Cause of disease: (Trigger: responsible, Theme: diarrheal diseases, Cause: Contaminated drinking water]
``` 
</details>


### 5. Machine Translation

**Task Introduction**

Machine translation can convert biomedical texts from one natural language to another. This task can assist in translating various medical questions and recommendations, disease names, symptoms, and other information between English and Chinese.

<details>
  <summary><b>Examples</b></summary>

**Chinese to English Translation Example**

**User Inputï¼š** 
``` 
å°†ä¸‹é¢æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼š
å…‰åŠ¨åŠ›ç–—æ³•ï¼ˆPDTï¼‰ä½œä¸ºä¸€ç§æ–°å…´çš„è‚¿ç˜¤æ²»ç–—æ‰‹æ®µï¼Œå› å…¶ä¸è‰¯ååº”è¾ƒå°‘ã€é¶å‘æ€§å¥½ã€å¯é‡å¤æ²»ç–—ç­‰ä¼˜ç‚¹ï¼Œå·²å¹¿æ³›åº”ç”¨äºä¸´åºŠå¤šç§è‚¿ç˜¤çš„æ²»ç–—ã€‚ç›¸æ¯”äºæ‰‹æœ¯ã€åŒ–ç–—åŠæ”¾ç–—ç­‰ä¼ ç»Ÿæ²»ç–—ç­–ç•¥ï¼Œå…‰åŠ¨åŠ›ç–—æ³•ä¸ä»…å¯æ€ä¼¤åŸä½è‚¿ç˜¤ï¼Œè¿˜å¯é€šè¿‡æ¿€æ´»æœºä½“çš„å…ç–«æ•ˆåº”å¯¹è½¬ç§»ç˜¤å‘æŒ¥æŠ‘åˆ¶ä½œç”¨ã€‚ç„¶è€Œï¼ŒPDTè¯±å¯¼å…ç–«æ•ˆåº”çš„é«˜ä½å—å¤šç§å› ç´ å½±å“ï¼ŒåŒ…æ‹¬å…‰æ•å‰‚åœ¨ç»†èƒå†…çš„å®šä½å’Œå‰‚é‡ã€å…‰å‚æ•°ã€è‚¿ç˜¤å†…çš„æ°§æµ“åº¦ã€å…ç–«åŠŸèƒ½çš„å®Œæ•´æ€§ç­‰ã€‚æœ¬æ–‡é’ˆå¯¹PDTä»‹å¯¼æŠ—è‚¿ç˜¤å…ç–«æ•ˆåº”çš„ç›¸å…³æœºåˆ¶ï¼Œä»¥åŠPDTå…ç–«æ•ˆåº”çš„ä¸»è¦å½±å“å› ç´ è¿›è¡Œç»¼è¿°ï¼Œä»¥æ¢è®¨PDTç”¨äºè‚¿ç˜¤æ²»ç–—çš„æœªæ¥å‘å±•æ–¹å‘ã€‚
``` 
**Taiyi Outputï¼š**
``` 
As a new tumor treatment method, photodynamic therapy (pdt) has been widely used in clinical practice because of its advantages of few side effects, good targeting, and repeatability. Compared with traditional treatment strategies, such as surgery, chemotherapy, and radiotherapy, pdt can not only kill the primary tumor, but also inhibit the metastatic tumor by activating the body's immune effect. However, the induction of immune effect by pdt is affected by many factors, including the localization and dose of photosensitizers in cells, light parameters, oxygen concentration in tumor, and the integrity of immune function. In this review, we focus on themechanisms of antitumor immune effect mediated by pdt, and the main influencing factors of immune effect of pdt, to discuss the future development direction of pdt in thetumor treatment.
``` 

**English to Chinese Translation Example**

**User Inputï¼š** 
``` 
Translate the following text into Chinese:
Metabolic-associated fatty liver disease (MAFLD), formerly known as non-alcoholic fatty liver disease (NAFLD), is one of the most popular chronic liver diseases in the world. There are many explorations on the epidemiology and risk factors of the disease published in recent years. With the increasing burden of MAFLD on medical care and social economy, drug treatment of MAFLD has become an urgent research hotspot. Based on this, the current epidemiological status, risk factors, diagnostic criteria and treatment of MAFLD were summarized in this review in order to enlighten the clinical practice and scientific research of MAFLD.
``` 
**Taiyi Outputï¼š**
``` 
ä»£è°¢ç›¸å…³è„‚è‚ªè‚ç—…(Metabolic Associated Fatty Liver Disease,MAFLD)åˆç§°éé…’ç²¾æ€§è„‚è‚ªæ€§è‚ç—…(Non Alcoholic Fatty Liver Disease,NAFLD)ï¼Œæ˜¯ç›®å‰å…¨çƒæœ€ä¸ºæµè¡Œçš„æ…¢æ€§è‚ç—…ä¹‹ä¸€ã€‚è¿‘å¹´æ¥ï¼Œå…³äºè¯¥ç—…çš„çš„æµè¡Œç—…å­¦å’Œå±é™©å› ç´ çš„æ¢ç´¢æ€§ç ”ç©¶é¢‡å¤šã€‚éšç€MAFLDå¯¹åŒ»ç–—å’Œç»æµçš„è´Ÿæ‹…æ—¥ç›ŠåŠ é‡ï¼Œå…¶è¯ç‰©æ²»ç–—å·²æˆä¸ºç ”ç©¶çš„çƒ­ç‚¹ã€‚åŸºäºæ­¤ï¼Œæœ¬æ–‡å¯¹è¯¥ç—…çš„æµè¡Œç—…å­¦ç°çŠ¶ã€å±é™©å› ç´ ã€è¯Šæ–­æ ‡å‡†å’Œæ²»ç–—è¿›è¡Œäº†æ€»ç»“,ä»¥æœŸä¸ºä¸´åºŠå®è·µå’Œç§‘å­¦ç ”ç©¶æä¾›å‚è€ƒã€‚
``` 
</details>


### 6. Title Generation

**Task Introduction**

Title generation aims to generate informative article titles for input biomedical text paragraphs with summarization.

<details>
  <summary><b>Examples</b></summary>

**Example in Chinese**

**User Inputï¼š** 
``` 
è¯·ç»™ä¸‹é¢æ‘˜è¦èµ·æ ‡é¢˜ï¼š
æ°”ç®¡é£Ÿç®¡ç˜˜æ˜¯æŒ‡æ°”ç®¡æˆ–æ”¯æ°”ç®¡ä¸é£Ÿç®¡ä¹‹é—´çš„ç—…ç†æ€§ç˜˜é“ï¼ŒåŒ…æ‹¬æ°”ç®¡-é£Ÿç®¡ç˜˜å’Œæ”¯æ°”ç®¡-é£Ÿç®¡ç˜˜ï¼Œä¸´åºŠä»¥æ°”ç®¡-é£Ÿç®¡ç˜˜è¾ƒå¤šè§ã€‚æ°”ç®¡é£Ÿç®¡ç˜˜è‡´ç—…åŸå› è¾ƒå¤šï¼Œå¯å¼•èµ·ä¸¥é‡çš„å¹¶å‘ç—‡ï¼Œæ˜¯å¯¹æ‚£è€…ç”Ÿæ´»è´¨é‡å½±å“æ˜¾è‘—ã€æ²»ç–—å›°éš¾å’Œç—…æ­»ç‡è¾ƒé«˜çš„ç–¾ç—…ã€‚æ°”ç®¡é£Ÿç®¡ç˜˜ç›®å‰æ²»ç–—æ–¹å¼è¾ƒå¤šï¼Œä½†å¤šæ•°ç–—æ•ˆæ¬ ä½³ï¼Œå¯¹æ–°å…´æ²»ç–—æ‰‹æ®µçš„éœ€æ±‚è¿«åˆ‡ã€‚èƒ¸è…¹éƒ¨Xçº¿æ‘„å½±æ£€å‡ºé¼»èƒƒç®¡æ»ç•™æ˜¯æ°”ç®¡é£Ÿç®¡ç˜˜è¯Šæ–­çš„é‡‘æ ‡å‡†ï¼Œå…¶ä¸»è¦æ²»ç–—æ–¹æ³•åŒ…æ‹¬å¤–ç§‘æ‰‹æœ¯æ²»ç–—ã€æ”¯æ¶ç½®å…¥ã€å±€éƒ¨ç”Ÿç‰©èƒ¶æ°´å°é—­ã€å¹²ç»†èƒæ²»ç–—ç­‰ã€‚æœ¬æ–‡ç»¼è¿°è¿‘å¹´æ°”ç®¡é£Ÿç®¡ç˜˜è¯Šæ–­ä¸æ²»ç–—çš„ä¸»è¦ç ”ç©¶è¿›å±•ï¼Œæ—¨åœ¨ä¸ºè¯¥ç—…çš„ä¸´åºŠè¯Šæ²»æä¾›å‚è€ƒã€‚
``` 
**Taiyi Outputï¼š**
``` 
æ°”ç®¡é£Ÿç®¡ç˜˜è¯Šæ–­ä¸æ²»ç–—è¿›å±•
``` 

**Example in English**

**User Inputï¼š** 
``` 
Output a title for the following abstract:
The incidence of diabetes mellitus has been increasing, prompting the search for non-invasive diagnostic methods. Although current methods exist, these have certain limitations, such as low reliability and accuracy, difficulty in individual patient adjustment, and discomfort during use. This paper presents a novel approach for diagnosing diabetes using high-frequency ultrasound (HFU) and a convolutional neural network (CNN). This method is based on the observation that glucose in red blood cells (RBCs) forms glycated hemoglobin (HbA1c) and accumulates on its surface. The study incubated RBCs with different glucose concentrations, collected acoustic reflection signals from them using a custom-designed 90-MHz transducer, and analyzed the signals using a CNN. The CNN was applied to the frequency spectra and spectrograms of the signal to identify correlations between changes in RBC properties owing to glucose concentration and signal features. The results confirmed the efficacy of the CNN-based approach with a classification accuracy of 0.98. This non-invasive diagnostic technology using HFU and CNN holds promise for in vivo diagnosis without the need for blood collection.
``` 
**Taiyi Outputï¼š**
``` 
A novel approach for diagnosing diabetes using high-frequency ultrasound and a convolutional neural network
``` 
</details>

### 7. Text Classification

**Task Introduction**

Biomedical text classification aims to automatically categorize biomedical texts into predefined class labels, aiding healthcare professionals, researchers, and institutions in better managing and analyzing medical information.

<details>
  <summary><b>Examples</b></summary>

**Example in Chinese**

**User Inputï¼š** 
``` 
ç°æœ‰ä»¥ä¸‹æ–‡æœ¬ï¼š
æ²»çš®è‚¤ç—…è´¹ç”¨å¤§æ¦‚å¤šå°‘ï¼Ÿ
è¯·å°†ä¸Šè¿°æ–‡æœ¬åˆ†ç±»è‡³æŒ‡å®šç±»åˆ«ä¸­ï¼šåŒ»ç–—è´¹ç”¨ï¼Œåæœè¡¨è¿°ï¼ŒæŒ‡æ ‡è§£è¯»ï¼Œç—…æƒ…è¯Šæ–­ï¼Œå°±åŒ»å»ºè®®ï¼Œç–¾ç—…æè¿°ï¼Œå…¶ä»–ï¼Œæ²»ç–—æ–¹æ¡ˆï¼Œç—…å› åˆ†æï¼ŒåŠŸæ•ˆä½œç”¨ï¼Œæ³¨æ„äº‹é¡¹
``` 
**Taiyi Outputï¼š**
``` 
ä¸Šè¿°æ–‡æœ¬è¢«åˆ†ç±»ä¸ºï¼šåŒ»ç–—è´¹ç”¨
``` 

**Example in English**

**User Inputï¼š** 
``` 
Document triage: "Will my mask from sherwin williams paint store with filters protect me from corona virus along with paint fumes?"
Labels: patient, doctor
``` 
**Taiyi Outputï¼š**
``` 
Result: patient
``` 
</details>

### 8. Text Semantic Similarity
**Task Introduction**

Text Semantic Similarity aims to determine the degree of association or similarity between two medical texts. This task typically involves text matching, similarity measurement, and semantic understanding and can be used in various applications such as medical information retrieval and document matching.

<details>
  <summary><b>Examples</b></summary>

**Example in Chinese**

**User Inputï¼š** 
``` 
è¯­å¥1ï¼šä¹™è‚å°äºŒé˜³ä¼šè½¬æˆå°ä¸‰é˜³å—ï¼Ÿ
è¯­å¥2ï¼šä¹™è‚å°ä¸‰é˜³ä¼šä¸ä¼šè½¬æˆè‚ç¡¬åŒ–ã€è‚ç™Œï¼Ÿ
è¯·ä»ä¸‹é¢é€‰é¡¹ä¸­è¯„ä¼°è¿™æ®µæ–‡æœ¬çš„è¯­ä¹‰ç›¸ä¼¼åº¦ï¼šè¯­ä¹‰ä¸ç›¸åŒï¼Œè¯­ä¹‰ç›¸åŒ
``` 
**Taiyi Outputï¼š**
``` 
è¯­ä¹‰ä¸ç›¸åŒ
``` 

**Example in English**

**User Inputï¼š** 
``` 
1. How can someone's happiness level affect someone's health?
2. Can staying happy improve my health? What specific steps should I take?
Assess the semantic similarity of the text pairs based on the following labels: dissimilar, similar
``` 
**Taiyi Outputï¼š**
``` 
similar
``` 
</details>

## Training Data

### Data Collection
To fully leverage existing biomedical natural language processing datasets, this project collected a total of 170 open-source datasets in both Chinese and English. Among these, there are 38 Chinese datasets covering 10 BioNLP tasks and 131 English datasets covering 12 BioNLP tasks. An overview of the datasets is provided in the following figure.

<p align="center">
    <br>
    <img src="./fig/data_overview.png?raw=true" width="1200" height="350"/>
    <br>
</p>

This project compiled information on each dataset, including task type, data scale, task description, and relevant data links. For specific details, please refer to the ["Overview of the Biomedical Datasets"](./data_file/dataset_inf.md).

### Standardized Data Format
To facilitate subsequent data conversion, this project drew inspiration from the [BigBio](https://github.com/bigscience-workshop/biomedical) project and, based on the type of tasks, devised a unified data format. For specific details about this standardized data format, please refer to the ["DUTIR-BioNLP Data Schema Documentation"](./data_file/Task_schemas_en.md), and the data has been transformed to adhere to this standardized format.

### Instruction-Tuning Data
After filtering and selecting datasets based on data quality, instructional templates were designed based on the [PromptCBLUE](https://github.com/michael-wzhu/PromptCBLUE) Project and data was transformed according to the standardized data format. The summary of the instruction-tuning data is presented in the following table:


<table >
<tr>
  <th>Task Type</th>
  <th>Chinese Data Scale</th>
  <th>English Data Scale</th>
</tr>
<tr>
  <td>Named Entity Recognition</td>
  <td align="center">44,667</td>
  <td align="center">28,603</td>
</tr>
<tr>
  <td>Relation Extraction</td>
  <td align="center">26,606</td>
  <td align="center">17,279</td>
</tr>
<tr>
  <td>Event Extraction</td>
  <td align="center">2,992</td>
  <td align="center">2,022</td>
</tr>
<tr>
  <td>Text Classification</td>
  <td align="center">37,624</td>
  <td align="center">40,339</td>
</tr>
<tr>
  <td>Text Pair Task</td>
  <td align="center">45,548</td>
  <td align="center">11,237</td>
</tr>
<tr>
  <td>Machine Translation</td>
  <td colspan ="2"; align="center">74,113</td>
</tr>
<tr>
  <td>Single-turn Question and Answer</td>
  <td align="center">129,562</td>
  <td align="center">57,962</td>
</tr>
<tr>
  <td>Multi-Round Dialogue</td>
  <td align="center">16,391</td>
  <td align="center">10,000</td>
</tr>
<tr>
  <td>Other Additional Tasks</td>
  <td colspan ="2"; align="center">9,370</td>
</tr>
<tr>
  <td>General Chain-of-Thought Data</td>
  <td align="center">50,000</td>
  <td align="center">7,473</td>
</tr>
<tr>
  <td>General Dialogue Data</td>
  <td colspan ="2"; align="center">390,000</td>
</tr>
<tr>
  <td>Total</td>
  <td colspan ="2"; align="center">1,001,788</td>
</tr>
</table>

For detailed information on the instructional data used for training, please refer to the ["Instruction-Tuning Data Details"](./data_file/final_instruction_data.md).


## Model Training
### Introduction to the Base Model

The current version of Taiyi is based on the [Qwen-7B-base](https://huggingface.co/Qwen/Qwen-7B) model, which has been fine-tuned through Instruct-tuning. Qwen-7B is a 7 billion-parameter model in the Alibaba Cloud's Qwen large model series. It has been pre-trained on over 200 trillion tokens, encompassing high-quality data in Chinese, English, multiple languages, code, mathematics, and more. The training corpus covers both general and specialized domains.


### Training Details

We conducted instruction-guided fine-tuning using Qlora on 6 Nvidia A40 48 GB GPUs. Our training code was modified based on project [Firefly](https://github.com/yangjianxin1/Firefly). The key hyperparameters used in the training process are as follows:


```
num_train_epochs:3
per_device_train_batch_size:12
gradient_accumulation_steps:2
earning_rate:0.0002
max_seq_length:1024
lr_scheduler_type:"constant_with_warmup"
warmup_ratio:0.1
lora_rank:64
lora_alpha:16
lora_dropout:0.05
weight_decay:0
max_grad_norm:0.3
```
Our training dataset consists of approximately 1 million training samples. Each epoch of training takes approximately two days to complete. 

## Model Usage
### Environment Setup

The environment configuration we used for training and testing is as follows:
```
torch==1.13.0
accelerate==0.21.0
transformers==4.30.2
peft==0.4.0
bitsandbytes==0.39.0
loguru==0.7.0
numpy
pandas==1.2.5
tqdm==4.62.3
deepspeed==0.9.5
tensorboard
sentencepiece
transformers_stream_generator
tiktoken
einops
scipy
```

To install all dependencies automatically using the command:
```
$ pip install -r requirements.txt
```

### Model Inference
We concatenate multi-turn dialogues into the following format, and then tokenize them. Where eod is the special character <|endoftext|> in the qwen tokenizer.

```
<eod>input1<eod>answer1<eod>input2<eod>answer2<eod>.....
```
The following code can be used to perform inference using our model:
```python

from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

model_name = "DUTIR-BioNLP/Taiyi-LLM"

device = 'cuda:0'

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    low_cpu_mem_usage=True,
    torch_dtype=torch.float16,
    trust_remote_code=True,
    device_map = device
)


model.eval()
tokenizer = AutoTokenizer.from_pretrained(
    model_name,
    trust_remote_code=True
)

import logging
logging.disable(logging.WARNING)
tokenizer.pad_token_id = tokenizer.eod_id
tokenizer.bos_token_id = tokenizer.eod_id
tokenizer.eos_token_id = tokenizer.eod_id
history_token_ids = torch.tensor([[]], dtype=torch.long)
max_new_tokens = 500
top_p = 0.9
temperature = 0.3
repetition_penalty = 1.0

# begin chat
history_max_len = 1000 
utterance_id = 0
history_token_ids = None

user_input = "Hiï¼Œcould you please introduce yourselfï¼Ÿ"

input_ids = tokenizer(user_input, return_tensors="pt", add_special_tokens=False).input_ids
bos_token_id = torch.tensor([[tokenizer.bos_token_id]], dtype=torch.long)
eos_token_id = torch.tensor([[tokenizer.eos_token_id]], dtype=torch.long)
user_input_ids = torch.concat([bos_token_id,input_ids, eos_token_id], dim=1)


model_input_ids = user_input_ids.to(device)
with torch.no_grad():
    outputs = model.generate(
        input_ids=model_input_ids, max_new_tokens=max_new_tokens, do_sample=True, top_p=top_p,
        temperature=temperature, repetition_penalty=repetition_penalty, eos_token_id=tokenizer.eos_token_id
    )

response = tokenizer.batch_decode(outputs)
print(response[0])
#<|endoftext|>Hiï¼Œcould you please introduce yourselfï¼Ÿ<|endoftext|>Hello! My name is Taiyi,.....<|endoftext|>
```


We provide two test codes for dialogue. You can use the code in ```dialogue_one_trun.py``` to test single-turn QA dialogue, or use the sample code in ```dialogue_multi_trun.py``` to test multi-turn conversational QA.


Note: To ensure fast inference speed, we recommend using a 4090 GPU.

## Overall Performance

<table >
<tr>
  <th>Task Type</th>
  <th>Dataset</th>
  <th>Taiyi</th>
  <th>ChatGPT3.5</th>
  <th>SOTA</th>  
</tr>
<tr>
  <td rowspan = '5'>NER(Micro-F1)</th>
  <td>BC5CDR-Chem</td>
  <td align="center">80.2</td>
  <td align="center">60.3</td>
  <td align="center">93.3(PubMedBERT)</td>  
</tr>
<tr>
  <td>BC5CDR-Dise</td>
  <td align="center">69.1</td>
  <td align="center">51.8</td>
  <td align="center">85.6(PubMedBERT)</td>  
</tr>
<tr>
  <td>CHEMDNER</td>
  <td align="center">79.9</td>
  <td align="center">36.5</td>
  <td align="center">92.4(BioBERT)</td>  
</tr>
<tr>
  <td>NCBIdisease</td>
  <td align="center">73.1</td>
  <td align="center">50.5</td>
  <td align="center">87.8(PubMedBERT)</td>  
</tr>
<tr>
  <td>CMeEE-dev</td>
  <td align="center">65.7</td>
  <td align="center">47.0</td>
  <td align="center">74.0(CBLUE)</td>  
</tr>
<tr>
  <td rowspan = '2'>RE(Micro-F1)</th>
  <td>BC5CDR</td>
  <td align="center">37.5</td>
  <td align="center">14.2</td>
  <td align="center">45.0(BioGPT)</td>  
</tr>
<tr>
  <td>CMeIE-dev</td>
  <td align="center">43.2</td>
  <td align="center">30.6</td>
  <td align="center">54.9(CBLUE)</td>  
</tr>
<tr>
  <td rowspan = '3'>TC(Micro-F1)</th>
  <td>BC7LitCovid</td>
  <td align="center">84.0</td>
  <td align="center">63.9</td>
  <td align="center">91.8(Bioformer)</td>  
</tr>
<tr>
  <td>HOC</td>
  <td align="center">80.0</td>
  <td align="center">51.2</td>
  <td align="center">82.3(PubMedBERT)</td>  
</tr>
<tr>
  <td>KUAKE_QIC-dev</td>
  <td align="center">77.4</td>
  <td align="center">48.5</td>
  <td align="center">85.9(CBLUE)</td>  
</tr>
<tr>
  <td rowspan = '3'>QA(Accuracy)</th>
  <td>PubMedQA</td>
  <td align="center">54.4</td>
  <td align="center">76.5</td>
  <td align="center">55.8(PubMedBERT)</td>  
</tr>
<tr>
  <td>MedQA-USMLE</td>
  <td align="center">37.1</td>
  <td align="center">51.3</td>
  <td align="center">36.7(BioBERT-large)</td>  
</tr>
<tr>
  <td>MedQA-MCMLE</td>
  <td align="center">64.8</td>
  <td align="center">58.2</td>
  <td align="center">70.1(RoBERTA-large)</td>  
</tr>
<tr>
  <td>ALL</th>
  <td>AVE</td>
  <td align="center">64.8</td>
  <td align="center">49.3</td>
  <td align="center">73.5</td>  
</tr>
</table>

## Limitation and Future Work

**Limitations**

The goal of this project is to explore the Chinese English bilingual natural language processing capabilities of the large model in the biomedical field. However, there are some shortcomings that must be considered in Taiyi model at present:

- Misunderstanding: Like all major language models, there is a risk of misunderstanding or misinterpretation, especially when dealing with specialized terminology or complex concepts in the biomedical field. In this case, our model may provide inaccurate answers or explanations.

- Hallucinations: Large language models sometimes generate meaningless or completely unrelated responses to a given input. This' hallucination 'may be particularly problematic when users are unfamiliar with the discussion topic, as they may not be able to easily identify errors in the model output.

- Limited information: Despite our commitment to becoming a comprehensive language model in the biomedical field, the knowledge of the model is still limited and may not cover all aspects of each field or profession. Users should be aware that the information in the model may not be comprehensive and use it with caution when in-depth or professional knowledge is needed.

- Bias: The training data of the model may contain biases, which may be reflected in the model's response. We strive to reduce bias, but we cannot completely eliminate it. Users should handle potential bias issues in model responses with caution.

- Limited long multi-turn conversational ability: Due to the current computational constraints of our team, the max token length we could set during training was 1024. Therefore, our current model is most competitive in relatively short conversations (around 5 turns).

- Limited topic switching ability: Due to current constraints on information and computational resources, our model may exhibit instability in multi-turn conversations covering multiple topics with large spans. Therefore, when conversing with Taiyi, users should try to maintain consistency in the dialogue topic.

Note: The Taiyi model is intended to provide information and knowledge, but should not be used as a substitute for medical professionals' advice or diagnosis. Any decision involving personal health should be consulted with professional medical personnel.

**Future Work**

- Open source data and technical manuscripts: Organize and improve data resources and model training technical manuscripts, and will be released as open source in the future.

- Continuing pretraining: Due to current computing resource limitations, the current version of Taiyi mainly performs instruction data fine-tuning and does not use massive biomedical resources to continue pretraining. In the future, this project will explore the use of large model bases in the biomedical field resources to futher pretraining.

- Reinforcement learning enhances performance: This project will explore how to further enhance the performance of models and align human intentions using reinforcement learning methods.

- Enhanced interpretability: Compared to the general field, the biomedical field requires higher interpretability of model prediction results. In the future, we will explore the interpretability methods of Taiyi on various BioNLP tasks.

- Enhanced security: Although security data has been added for training in this project, model security in the biomedical field is still insufficient. We will continue to explore how to use biomedical knowledge bases to enhance model security.
  
- ......

## Development Team
Taiyi was developed by the [Dalian University of Technology Information Retrieval Research Laboratoryï¼ˆDUTIRï¼‰](http://ir.dlut.edu.cn/) 

Supervisors: [Ling Luo](http://faculty.dlut.edu.cn/luoling/en/index.htm), Zhihao Yang, Jian Wang, Yuanyuan Sun, Hongfei Lin

Student Members: Jinzhong Ning, Yingwen Zhao, Zeyuan Ding, Peng Chen, Weiru Fu, Qinyu Han, Guangtao Xu, Yunzhi Qiu, Dinghao Pan, Jiru Li, Zhijun Wang, Hao Li, Wenduo Feng, Senbo Tu, Yuqi Liu


## Acknowledgements
The work of this project has been inspired and assisted by the following open-source projects and technologies. We would like to express our gratitude to the developers and contributors of these projects, including but not limited to:
- Qwen: https://github.com/QwenLM/Qwen
- Firefly: https://github.com/yangjianxin1/Firefly
- BigBIO: https://github.com/bigscience-workshop/biomedical
- PromptCBLUE: https://github.com/michael-wzhu/PromptCBLUE
- The Taiyi logo was synthesized by ERNIE Bot

## Disclaimer
The resources related to this project are for academic research purposes only and are strictly prohibited from commercial use. The use of the source code of this warehouse follows the open source license agreement [Apache 2.0](https://github.com/DUTIR-BioNLP/Taiyi-LLM/blob/main/LICENSE).
During use, users are required to carefully read and comply with the following statements:
1. Please ensure that the content you input does not infringe on the rights and interests of others, does not involve harmful information, and does not contain any content related to politics, violence, or pornography, and all input content is legal and compliant.
2. Please confirm and be aware that all content generated using the Taiyi model is generated by artificial intelligence models, and the generated content is not entirely rational. This project does not guarantee the accuracy, completeness, and functionality of the generated content, nor assumes any legal responsibility.
3. Any responses that violate laws, regulations, public order, or good customs in this model do not represent the attitude, viewpoint, or stance of this project. This project will continuously improve the model responses to make them more in line with social ethics and moral norms.
4. For any content output by the model, the user shall bear their own risks and responsibilities. This project does not assume any legal responsibility, nor shall they be liable for any losses that may arise from the use of relevant resources and output results.
5. The third-party links or libraries appearing in this project are for convenience only, and their content and viewpoints are not related to this project. Users need to distinguish themselves when using, and this project does not assume any joint liability;
6. If users discover any significant errors in the project, please provide feedback to us to help us fix them in a timely manner.


By using this project, you have carefully read, understood, and agreed to abide by the above disclaimer. This project reserves the right to modify this statement without prior notice to anyone.


## Citation
If you use the repository of this project, please cite it.
```
@misc{taiyi,
    author = {Taiyi-Team}.
    title = {Taiyi: A Bilingual Fine-Tuned Large Language Model for Diverse Biomedical Tasks}
    year = {2023},
    publisher = {GitHub},
    journal = {GitHub repository}
    howpublished = {\url{https://github.com/DUTIR-BioNLP/Taiyi-LLM}}
}
```

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=DUTIR-BioNLP/Taiyi-LLM&type=Date)](https://star-history.com/#DUTIR-BioNLP/Taiyi-LLM&Date)


 
